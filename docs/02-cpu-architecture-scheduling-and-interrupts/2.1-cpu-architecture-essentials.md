# 2.1 CPU Architecture Essentials

This document introduces the physical and logical structure of modern CPUs as seen by Linux. It focuses on how cores, hardware threads, caches, and frequency scaling shape performance, and how you can *observe* these details using standard tools.

The goal is not to turn you into a CPU designer, but to give you enough intuition to reason about why a workload is fast or slow, noisy or stable, and what “CPU-bound” really means in practice.

---

## 2.1.1 Key Terms

- **CPU core**  
  An independent execution unit that can run instructions. A modern server has multiple cores per socket.

- **Hardware thread (logical CPU)**  
  A schedulable execution slot exposed to the OS, often created by technologies like Hyper-Threading (two hardware threads per core).

- **Socket**  
  A physical CPU package on the motherboard. A dual-socket system has two CPU packages, each with its own cores and caches.

- **Cache hierarchy (L1/L2/L3)**  
  Small, fast memories built into the CPU that store recently used data. Think of them as a chef's countertop (fast access) versus the pantry down the hall (RAM, slower access). L1 is smallest and fastest, L3 is largest but still much faster than RAM.

- **NUMA (Non-Uniform Memory Access)**  
  On multi-socket systems, memory attached to one CPU socket is faster to access from that socket's cores than from the other socket's cores. Like having two kitchens—each chef works faster using their own kitchen's pantry.

- **Clock frequency (GHz)**  
  How many billions of cycles per second a CPU core runs. Modern CPUs adjust frequency dynamically: lower when idle (to save power), higher during bursts of work (turbo/boost), and sometimes lower under sustained heavy load (thermal limits).

- **CPU-bound workload**  
  A workload where adding more CPU capacity (cores or speed) makes it faster, and where you see high CPU usage (`%us` or `%sy` in `top`) with low I/O wait (`%wa`).

All of these terms will be used and explained in the sections that follow.

---

## 2.1.2 Why CPU Architecture Matters for Performance

From a distance, a CPU looks like a single number in `top`: `%Cpu(s): 85.3 us, 3.1 sy, ...`. Under the hood, that number hides:

- How many *cores* you have.
- How many *hardware threads* (logical CPUs) per core.
- How effective your *caches* are.
- Whether your workload is *CPU-bound* or blocked on something else.

An analogy:

- Imagine a restaurant kitchen.
- **Cores** are chefs.
- **Hardware threads** are each chef’s two hands; they can work on two tasks, but they still share one brain and one body.
- **Caches** are ingredients on the counter; RAM is the pantry down the hallway.
- If the chefs constantly run back to the pantry, service slows down – even if everyone is working hard.

Linux exposes this structure via `/proc/cpuinfo`, `/sys/devices/system/cpu/`, and tools like `lscpu`, `nproc`, and `htop`. Understanding this structure helps you answer questions such as:

- Do I really have free CPU capacity, or am I saturating certain cores only?
- Is Hyper-Threading helping this workload, or just adding noise and contention?
- Is performance limited by raw CPU cycles, memory latency, or cache behavior?

---

## 2.1.3 Seeing Cores, Sockets, and Threads with lscpu

The `lscpu` command summarizes the CPU topology from `/proc/cpuinfo` and sysfs.

```bash
lscpu
```

Sample (abridged) output:

```text
Architecture:        x86_64
CPU(s):              8
On-line CPU(s) list: 0-7
Thread(s) per core:  2
Core(s) per socket:  4
Socket(s):           1
NUMA node(s):        1
Model name:          Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
CPU MHz:             2399.996
NUMA node0 CPU(s):   0-7
```

Key fields and how to interpret them:

- **CPU(s)**  
  Total number of hardware threads (logical CPUs) available to Linux.

- **Thread(s) per core**  
  How many hardware threads share one physical core. Value >1 indicates Hyper-Threading or similar.

- **Core(s) per socket** and **Socket(s)**  
  Multiply these together and then by threads-per-core to cross-check against `CPU(s)`.

- **NUMA node(s)** and `NUMA nodeX CPU(s)`  
  Show which logical CPUs belong to each memory node.

For performance investigation, always translate “CPU is 90% busy” into “how many cores and threads are doing work?” A load of 7 on an 8-thread system means something entirely different from 7 on a 64-thread system.

---

## 2.1.4 CPU Topology in Linux: A Visual Overview

The following Mermaid diagram shows a simplified single-socket system with 4 cores and 2 hardware threads per core:

```mermaid
graph TD
    A[Socket 0] --> B[Core 0]
    A --> C[Core 1]
    A --> D[Core 2]
    A --> E[Core 3]

    B --> B0[CPU 0]
    B --> B1[CPU 1]
    C --> C0[CPU 2]
    C --> C1[CPU 3]
    D --> D0[CPU 4]
    D --> D1[CPU 5]
    E --> E0[CPU 6]
    E --> E1[CPU 7]

    A --- L3[L3 Cache (shared)]
    B --- L2B[L2 Cache]
    C --- L2C[L2 Cache]
    D --- L2D[L2 Cache]
    E --- L2E[L2 Cache]
```

This diagram visualizes how physical hardware maps to the logical IDs used by the OS. Here is how to read it in the context of Linux tools:

- **Logical IDs match the diagram**: `CPU 0..7` correspond exactly to the processor numbers seen in `lscpu` and `htop`.
- **Cache proximity explains interference**:
  - **L1/L2 (Roommates)**: Shared by threads on the same core (e.g., CPU 0 and 1). These threads fight intensely for this tiny, ultra-fast space.
  - **L3 (Community Pool)**: Shared by all cores on the socket. A heavy task on CPU 0 can accidentally evict data needed by CPU 6, causing "noisy neighbor" issues across the whole chip.

### Understanding Hardware Threads: When Two Logical CPUs Share One Core

When you run `lscpu` and see "Thread(s) per core: 2", it means each physical core presents *two* logical CPUs to Linux. This is called **Hyper-Threading** (Intel) or **SMT** (AMD).

Think of it this way:
- One physical core is like a single chef.
- Two hardware threads are like the chef's two hands—they can juggle multiple tasks, but they still share one brain, one body, and one workspace.

**When does this help?**

Hyper-Threading works well when threads are *waiting* for something:
- One thread is waiting for data from RAM → the other thread can use the core's execution units.
- One thread is blocked on I/O → the other thread keeps the core busy.

**When does this hurt?**

When both threads are doing heavy computation at the same time, they compete for the core's resources and can slow each other down.

#### What You'll Observe in `htop`

Run `htop` and press `t` to see a tree view showing which logical CPUs belong to which physical cores.

On a system with 4 cores and Hyper-Threading (8 logical CPUs total):
- CPU 0 and CPU 1 share Core 0
- CPU 2 and CPU 3 share Core 1
- CPU 4 and CPU 5 share Core 2
- CPU 6 and CPU 7 share Core 3

**Scenario 1: Good distribution**
```
CPU 0: [||||||||||||||||||||100%]  ← Core 0, thread 0 busy
CPU 1: [|                      5%]  ← Core 0, thread 1 idle
CPU 2: [||||||||||||||||||||100%]  ← Core 1, thread 0 busy
CPU 3: [|                      5%]  ← Core 1, thread 1 idle
```
Two compute threads on separate physical cores → good performance.

**Scenario 2: Bad distribution (contention)**
```
CPU 0: [||||||||||||||||||||100%]  ← Core 0, thread 0 busy
CPU 1: [||||||||||||||||||||100%]  ← Core 0, thread 1 busy (same core!)
CPU 2: [|                      5%]  ← Core 1 idle
CPU 3: [|                      5%]  ← Core 1 idle
```
Two compute threads on the *same* physical core → they compete for the core's single set of execution units (like two hands fighting for one knife).

**Example**: If both threads act as "number crunchers" (e.g., video encoding or encryption), they block each other because the core can only perform one math operation at a time. They will run significantly slower than if they were on separate cores.

**What this looks like system-wide:**
- Overall CPU usage might show only 25% (2 out of 8 logical CPUs busy).
- But those 2 logical CPUs are fighting over 1 physical core.
- Your application feels slow despite "plenty of free CPU."

**Key takeaway**: When investigating performance, always check *which* logical CPUs are busy, not just *how many*. Use `htop` with per-CPU view to spot this pattern.

---

## 2.1.5 Cache Hierarchy and Why It Matters

Modern CPUs have small, fast memories called **caches** built directly into the chip. These caches store copies of recently used data so the CPU doesn't have to wait for slower main memory (RAM) on every access.

### The Three Cache Levels

Think of a chef working in a kitchen:

- **L1 cache** (tens of KB per core)  
  Ingredients in the chef's hands. Tiny, but instantly available.

- **L2 cache** (hundreds of KB per core)  
  Nearby countertop. Larger, takes a moment to reach.

- **L3 cache** (several MB, shared across all cores in a socket)  
  Common prep table in the kitchen. Even larger, shared by all chefs.

- **RAM** (gigabytes)  
  Pantry down the hall. Huge, but requires a walk to fetch anything.

### Why This Matters for Performance

**When data fits in cache:**
- The CPU can process it very quickly.
- You see high CPU usage and good throughput.

**When data doesn't fit in cache (cache misses):**
- The CPU must wait for RAM, which is 50-100x slower than L1 cache.
- You see high CPU usage but *low* throughput—the CPU is busy waiting, not computing.

### What You'll Observe

Cache problems often show up as:

1. **High CPU usage with disappointing throughput**  
   The CPU is pegged at 100%, but work completes slowly.

2. **Performance that changes dramatically with data size**  
   Processing 10 MB is fast, but 100 MB is more than 10x slower—even though the algorithm is the same.

3. **Low `%sy` (system time) and low `%wa` (I/O wait) in `top`**  
   The CPU isn't blocked on I/O or syscalls, yet performance is poor.

### Seeing Cache Behavior with `perf stat` (Preview)

You can measure cache performance using the `perf` tool. Don't worry if this looks complex—we'll explore `perf` in more detail in later sections. For now, here's a simple example:

```bash
sudo perf stat -e cycles,instructions,cache-references,cache-misses -- \
    sha256sum /bin/bash
```

Sample output:
```
 Performance counter stats for 'sha256sum /bin/bash':

     1,234,567,890      cycles
       987,654,321      instructions              #    0.80  insn per cycle
        12,345,678      cache-references
         1,234,567      cache-misses              #   10.00% of all cache refs
```

**What to look for:**
- **insn per cycle** (instructions ÷ cycles): Higher is better. Low values (<0.5) often indicate the CPU is stalling.
- **cache-misses**: A high percentage (>10%) suggests poor cache locality.

**Key takeaway**: Cache behavior is invisible in `top`, but it dramatically affects how much work your CPU can do per second. Data access patterns matter as much as raw CPU speed.

---

## 2.1.6 NUMA Basics and Cross-Node Penalties

### What Is NUMA and Why Does It Exist?

Imagine you want to build a powerful server with lots of CPU cores and lots of RAM. There's a physical problem: as you add more and more cores to a single CPU chip, it becomes harder for all of them to share access to the same pool of memory. The wires connecting cores to RAM become a bottleneck—like too many cars trying to use the same highway exit.

**NUMA** (Non-Uniform Memory Access) is the solution to this problem. Instead of having one CPU with 64 cores fighting over one memory pool, you have:
- **Two separate CPUs** (sockets), each with 32 cores
- **Two separate memory pools**, one attached to each CPU
- Each CPU can access its **own** memory very quickly (local access)
- Each CPU can **also** access the **other** CPU's memory, but more slowly (remote access)

Think of it like two separate offices:
- **Without NUMA** (single socket): One huge office with 64 desks and one filing cabinet. Everyone crowds around the same cabinet.
- **With NUMA** (dual socket): Two offices, each with 32 desks and its own filing cabinet. Workers in Office A use Cabinet A (fast). If they need something from Cabinet B, they walk to Office B (slower, but still possible).

**The purpose of NUMA**: It lets you build servers with more total CPU cores and more total RAM than would be practical with a single CPU package, while keeping most memory accesses fast.

### Does NUMA Apply to Your System?

Most single-socket systems (laptops, desktops, small servers) are **not** NUMA. If you have only one physical CPU package, you can skip this section.

To check:

```bash
lscpu | grep "NUMA node"
```

If you see `NUMA node(s): 1`, your system is effectively non-NUMA (or UMA—Uniform Memory Access). If you see `NUMA node(s): 2` or more, read on.

### Seeing NUMA Layout

```bash
numactl --hardware
```

Example output from a dual-socket system:

```text
available: 2 nodes (0-1)
node 0 cpus: 0 1 2 3 4 5 6 7
node 1 cpus: 8 9 10 11 12 13 14 15
node 0 size: 64000 MB
node 1 size: 64000 MB
node distances:
node   0   1
  0:  10  21
  1:  21  10
```

**What this means:**
- Node 0 has CPUs 0-7 and 64 GB of RAM.
- Node 1 has CPUs 8-15 and 64 GB of RAM.
- Accessing local memory (distance 10) is faster than accessing remote memory (distance 21).

### The Kitchen Analogy

Think of two separate kitchens:
- **Local access**: A chef in Kitchen 0 grabs ingredients from Kitchen 0's pantry. Fast.
- **Remote access**: A chef in Kitchen 0 walks to Kitchen 1's pantry. Slower.

### What You'll Observe

NUMA problems show up as:

1. **Uneven CPU utilization**  
   One socket is hot (high CPU usage), the other is mostly idle, yet performance is poor.

2. **Unexpectedly high latency**  
   A process running on node 1 is constantly accessing memory allocated on node 0.

3. **Visible in `numastat`**  
   Run `numastat` to see per-node memory statistics:
   ```bash
   numastat
   ```
   Look for high `numa_foreign` or `other_node` counts, which indicate cross-node memory access.

### When to Worry About NUMA

- **Single-socket systems**: Don't worry. NUMA doesn't apply.
- **Multi-socket systems with well-behaved workloads**: Linux usually handles NUMA automatically.
- **Multi-socket systems with performance problems**: Check `numastat` and CPU distribution. You may need to pin processes to specific nodes with `numactl --cpunodebind` and `--membind`.

**Key takeaway**: On single-socket systems, ignore NUMA. On multi-socket servers, be aware that memory location matters, and use `numactl --hardware` and `numastat` to investigate uneven performance.

---

## 2.1.7 Frequency Scaling, Turbo, and Thermal Limits

Modern CPUs don't run at a fixed speed. The **clock frequency** (measured in GHz) changes dynamically based on workload and temperature:

- **Idle**: Frequency drops to save power (e.g., 800 MHz).
- **Burst workload**: Frequency increases temporarily (turbo/boost, e.g., 3.5 GHz).
- **Sustained heavy load**: Frequency may drop back down if the CPU gets too hot (thermal throttling).

### Seeing Current CPU Frequencies

Check the current frequency of each CPU:

```bash
grep 'cpu MHz' /proc/cpuinfo
```

Sample output:
```text
cpu MHz     : 2400.123
cpu MHz     : 2399.987
cpu MHz     : 3499.456  ← This CPU is in turbo
cpu MHz     : 2400.001
```

To watch frequencies change in real time:

```bash
watch -n 1 "grep 'cpu MHz' /proc/cpuinfo | head"
```

If you have `cpupower` installed (from the `linux-tools` package), you can get more details:

```bash
cpupower frequency-info
```

### What You'll Observe

**Scenario 1: Short bursts of work**
- Frequency jumps to turbo levels (3+ GHz).
- Work completes quickly.
- Frequency drops back to idle.

**Scenario 2: Sustained heavy load**
- Frequency starts high (turbo).
- After 10-30 seconds, frequency drops as the CPU heats up.
- Performance becomes slower over time, even though CPU usage stays at 100%.

**Scenario 3: Thermal throttling**
- CPU temperature reaches its limit (often 80-100°C).
- Frequency drops significantly below base frequency.
- You see 100% CPU usage in `top`, but throughput is terrible.
- Check `dmesg` for thermal warnings:
  ```bash
  dmesg | grep -i thermal
  ```

### Performance Implications

- **Benchmarking**: Always run benchmarks multiple times. The first run may be faster (turbo) than subsequent runs (thermal limits).
- **"It was fast yesterday"**: Check ambient temperature, fan operation, and dust buildup. A hot room or clogged fan can cause thermal throttling.
- **Power management**: Some servers have BIOS settings that limit turbo or lock frequency. Check your BIOS/UEFI settings if performance seems capped.

**Key takeaway**: CPU frequency is not constant. Use `grep 'cpu MHz' /proc/cpuinfo` to see actual running frequencies, and check `dmesg` for thermal warnings if performance degrades under sustained load.

---

## 2.1.8 Identifying CPU-Bound Workloads

A workload is **CPU-bound** when increasing CPU capacity (more cores or higher frequency) significantly improves throughput or latency, and other subsystems (disk, network) are not saturated.

You can get an initial sense with `top` or `htop`:

```bash
top
```

Look for:

- High `%us` (user) and `%sy` (system) with low `%wa` (I/O wait).
- One or more processes near 100% CPU on a single logical CPU.
- Load average roughly proportional to the number of busy CPUs.

For a more detailed view, use `pidstat` (from `sysstat`) or `perf top` to see which functions or instructions are consuming CPU.

Once you know a workload is CPU-bound, Section 02 as a whole helps you reason about *why*: poor cache usage, contention between hardware threads, NUMA penalties, or simply not enough cores.

---

## 2.1.9 Hands-On Exercise: Saturating a Single Core

> **Warning:** Run this only on a non-production system. It will temporarily fully utilize one logical CPU.

Use this small script to create a CPU-bound workload and observe it from Linux tools.

Associated script: `scripts/section02-01-cpu-architecture-demo.sh`.

Run it as:

```bash
bash scripts/section02-01-cpu-architecture-demo.sh
```

While it runs, in another terminal:

- Run `top` and watch a single process stay near 100% on one CPU.
- Run `lscpu` to see how many logical CPUs you have.
- Compare the single hot CPU to total capacity.

Questions to ask yourself:

- On a system with 8 logical CPUs, does 100% on one CPU mean the *system* is fully loaded?
- What happens if you increase the number of worker processes in the script?

---

## 2.1.10 Beginner Checklist

- [ ] I can run `lscpu` and explain the difference between sockets, cores, and hardware threads (logical CPUs).
- [ ] I can use `htop` to see per-CPU usage and identify when two busy logical CPUs share the same physical core.
- [ ] I can describe what CPU caches are using the kitchen analogy and explain why cache misses hurt performance.
- [ ] I can check if my system is NUMA with `lscpu | grep "NUMA node"` and explain when NUMA matters (multi-socket servers).
- [ ] I can view current CPU frequencies with `grep 'cpu MHz' /proc/cpuinfo` and explain why frequency changes (idle, turbo, thermal throttling).
- [ ] I can use `top` to identify CPU-bound workloads by looking for high `%us` or `%sy` with low `%wa`.
- [ ] I can run `section02-01-cpu-architecture-demo.sh` and observe a single CPU at 100% in `top` or `htop`.
- [ ] I can explain why "CPU is 90%" is incomplete without knowing how many cores and threads are available.
